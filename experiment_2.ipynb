{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading dataset\n",
    "import kaggle\n",
    "import os\n",
    "\n",
    "path = \"artifacts/dataset/\"\n",
    "dataset = \"palaksood97/resume-dataset\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    kaggle.api.dataset_download_files(dataset= dataset, path= path, unzip= True)\n",
    "    print(f\"Dataset: {dataset} downloaded successfully! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achyuth\n",
      "540-999-8048\n",
      "achyuth.java88@gmail.com\n",
      "\n",
      "OBJECTIVE:\n",
      "Around 8 years of strong software experience in design, development, analysis and deployment of web-based and Client-Server business applications using Object Oriented Analysis and Design (OOAD, OOPS) and Java/JEE/J2EE technologies in Financial, Insurance, and Health Sector Domain with Software Development Life Cycle (SDLC).\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "Actively involved in each phase of Software Development Life cycle (SDLC).\n",
      "Expertise in client scripting language and server scripting languages like HTML5, CSS3, JavaScript, JQuery, Ajax, AngularJS, NodeJS, JSON, Bootstrap.\n",
      "Utilized Java 1.8 features like Lambda expressions and Stream API for Bulk data operations on Collections which would increase the performance of the Application\n",
      "Hands on experience with Amazon web services (AWS) and Amazon cloud technologies such as Amazon EC2 (virtual servers) and Amazon Cloud Watch (monitoring).\n",
      "Managed Amazon Web Services like EC2, S3 bucket, ELB, Auto-Scaling, SNS, SQS, AMI, IAM, Dynamo DB, Elastic search, Virtual Private Cloud (VPC) through AWS Console and API Integration.\n",
      "Extensive experience working in Spring framework, Struts framework, ORM Mapping Hibernate framework and web services.\n",
      "Experience using Spring MVC, Spring Boot, Spring Cloud, Spring DAO, Spring Data, Spring IOC, Spring Annotations, Spring AOP, Spring Transactions and Spring Security.\n",
      "Experience in developing applications using Micro Services architecture.\n",
      "Expertise in developing reliable and scalable enterprise applications using Servlets, JSPs, Struts, JSTL, JDBC, AJAX, EJB and Web Services.\n",
      "Strong work experience in application integration and communicating using SOA, Web Services such as Simple Object Access Protocol(SOAP), Representational State Transfer (REST/ Restful), JAX-RPC, JAX-RS, JAX-WS, WSDL, UDDI, Apache CXF, JAXB, XSD, Axis2.\n",
      "Excellent knowledge and experience in writing SQL queries, Stored Procedures, Triggers and views using various databases such as MS SQL Server, MySQL, IBM DB2, Oracle databases and NoSQL database systems like Mongo DB.\n",
      "Expertise in XML technologies such as XSL, XSLT, XML schemas, XPath, XSL-FO and parsers like SAX, DOM.\n",
      "Experienced in JMS over messaging to exchange the information in more reliable and asynchronous way in enterprise Applications. Used Apache Active MQ and Apache Camel as JMS provider.\n",
      "Experience in Creating and configuring the continuous delivery pipelines for deploying Micro services and lambda functions using Jenkins CI server.                         \n",
      "Experience in developing logging and standard mechanism based on Log4j and SLF4j. \n",
      "Worked on implementing full life cycle of software development process (SDLC) in using version control tools like Git, Rational Clear Case, Tortoise SVN, CVS (Concurrent Version System).\n",
      "Hands-on experience working with Continuous Integration (CI) build-automation tools such as Jenkins along with Build Plugins like Maven, Gradle and Apache Ant.\n",
      "Experienced in the formation and mentoring of project teams working on Agile methodologies to deliver business critical software applications using tools like Jira.\n",
      "Experience in web development tools like Eclipse, RAD, Spring Tool Suite, and IntelliJ.\n",
      "Hands on experience with Windows, UNIX and Linux Environments.\n",
      "Experience in designing, developing, and deploying J2EE applications on IBM Web sphere, Web logic, Apache Tomcat, Glassfish and JBOSS Servers.\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Client: Capital One\t\t\t\t\t\t\t\t\t\t            Mar 17 – Till date             \n",
      "Location: Mclean, VA\n",
      "Role:  Full Stack Java Developer\n",
      "\n",
      "Description: Capital One is the one of largest banking sector, it has over 480,000 members and is among the top 20 credit unions in the U.S.A. Capital One Home Loans servicing is a diversified bank that offers a variety of checking, savings, mortgage and lending accounts and services to individuals, small businesses and commercial clients.\n",
      "\n",
      "Responsibilities:\n",
      "Involved in the complete SDLC (software development life cycle) of the application from requirement analysis to testing. \n",
      "Followed Agile Methodology in analyze, define, and document the application, which will support functional and business requirements. Coordinate these efforts with Functional Architects. \n",
      "Extensively worked on Responsive Web Design (RWD) page development using HTML5, CSS3, JQuery, JavaScript, AngularJS, and JSON.\n",
      "Utilized Java 1.8 features like Lambda expressions and Stream API for Bulk data operations on Collections which would increase the performance of the Application.\n",
      "Used Java 1.8 features in developing the code like Lambda expressions, creating resource classes, fetching documents from database. \n",
      "Deployed and Monitored Micro Services Using Pivotal Cloud Foundry, also Managed Domains and Routes with the Cloud Foundry.\n",
      "Designed, Configured and deployed Amazon Web Services (AWS) for a multitude of applications utilizing the Amazon cloud formation.\n",
      "Experienced in setting up Amazon EC2 instances, virtual private cloud (VPCs), and security groups. Setting up databases in AWS using RDS, storage using S3 bucket and configuring instance backups to S3 bucket.\n",
      "Implemented the application using Spring IOC, Spring MVC Framework, Spring Batch, Spring Boot and handled the security using Spring Security.\n",
      "Developed RESTful API for assessment indicators module and token based authentication for RESTful services using Spring Security.\n",
      "Involved in building database Model, APIs and Views utilizing Python, to build an interactive web based solution. \n",
      "Used Jersey to implement Restful Web Service and used XML form to transfer the data. \n",
      "Developed the application using J2EE Design Patterns like Business Delegate, Factory, Singleton, Session Facade, Service Locator and DAO. \n",
      "Worked and involved in deployment of core platform technologies, techniques, and web app frameworks such as spring, JBOSS, Tomcat, JSON, XML, HTML5, and Web Services.\n",
      "Used Spring MVC module to develop MVC Architecture. \n",
      "Worked on Apache Camel, RabbitMQ for sending messages over queue. \n",
      "Deployed the Application into Docker container and made easily accessible at runtime using Cloud Foundry and other cloud services like AWS, Netflix Eureka.\n",
      "Used Spring Security and OAuth2.0 for Authentication and Authorization of the application.\n",
      "Implemented Spring AOP for declarative transaction management.\n",
      "Developed a AWS Lambda function to send a request for internal service end points through API Gateway using apache HTTP Client. \n",
      "Managed code versioning with GitHub and deployment to staging and production servers\n",
      "Used Rest Controllers to replace the existing operations layer, which acts as bridge between business layer and the UI. \n",
      "Used Jenkins as build management tool for continuous integration process.\n",
      "Configured pom.xml to deploy the project using Maven.\n",
      "Provided Technical support for production environments resolving the issues, analyzing the defects, providing and implementing the solution defects. \n",
      "\n",
      "Environment: Agile Methodology, Java1.8, Lambda, J2EE, HTML5, CSS3, JavaScript, JQuery, AJAX, AngularJS, Bootstrap, JSON, JSP, AWS, Micro Services, Oracle, RabbitMQ, Spring AOP, Hibernate, Spring Cloud, Spring MVC, Spring JDBC, JDBC, Web-Services, SOA (Service-oriented) Architecture, Redis, REST, JAX-RS, Jersey, JUnit, JAX-B, WebSphere, JIRA, Maven, GIT, RAD, Jenkins, MongoDB,  Cassandra,.\n",
      "\n",
      "Client: State Farm\t\t\t\t\t\t\t\t\t\t                 Jan 16 – Feb 17 \n",
      "Location: Dallas, TX\n",
      "Role: JAVA Full Stack Developer\n",
      "\n",
      "Description: Auto Quote Purchase (AQP) application is one of the many applications that are part of SF Auto Systems. Property and Causality being the main forte of State Farm's business the maintenance of all the applications coming under the Auto Systems umbrella is crucial. Auto Quote Purchase (AQP) is one of the many applications that are part of SF Auto Systems. P&C Application support involves production support, defect fixes and minor enhancements based on the SF's requirement. AQP is a web application which is used to gather customer information, generate quote and provides options to purchase the Auto policies. \n",
      "\n",
      "Responsibilities:\n",
      "Involved in SDLC requirements gathering, analysis, design, development and testing of application developed using AGILE methodology.\n",
      "Created user-friendly GUI interface using HTML5, CSS3, JavaScript, JQuery, AngularJS.\n",
      "Implemented persistence framework using Hibernate& Handled Transaction Management using the provided data source.\n",
      "Responsible for designing Hibernate mapping files based on business logic and Object relationships.\n",
      "Developed restful web service APIs using Spring Framework such as Spring Core, Spring MVC, Spring \n",
      "AOP and Java Persistence API with a backend PostgreSQL and Cassandra database.\n",
      "Involved in developing Web Services to send XML request and reading the response SOAP UI from Java platform.\n",
      "Consumed Web Services to interact with other external interfaces to exchange the data in the form of XML and by using SOAP.\n",
      "Created Restful Web services using Jersey API (JAX-RS) while data exchange was carried out between application and services using JSON. \n",
      " Spring MVC, Ajax and Dependency Injection for handling presentation and business logic.\n",
      "To maintain loose coupling between layers published the business layer as services and injected the necessary dependent components using Spring IOC and published cross cutting concerns like Logging, User Interface exceptions, Transactions using Spring AOP.\n",
      "Integrated spring and hibernate together and worked on developing backend components and services using Hibernate and spring.\n",
      "Extensively used HQL and SQL for querying databases. \n",
      "Developed Message Driven Bean for asynchronous sending Messages using JMS.\n",
      "Used Apache Camel Framework to transform, extract and load the data.\n",
      "Used Spring Core Annotations for Dependency Injection and used Apache Camel to integrate spring framework. \n",
      "Implemented request and response objects using SOAP web services and created routes using Apache Camel. \n",
      "Used Rest methodology for the service layer interface and used JSON for the data transformation.\n",
      "Developed various AJAX and JSON calls for the communication between the server and the UI.\n",
      "Developed web services for produce and consumed the services by making Web Service Calls to remote services in different applications.\n",
      "Used Spring JMS module for lookup for the queues and MDBs for the listeners \n",
      "Established Database Connectivity using Hibernate O/R mapping with Spring ORM for MySQL Server. \n",
      "Developed the Mapping Resource Files for the database entities.\n",
      "Packaged and deployed the application in IBM Web sphere.\n",
      "Used IntelliJ as IDE to develop the application and followed the standard features for debugging and running.\n",
      "Used log4J for application logging and notification tracing mechanisms.\n",
      "Analysis and Bug fixing of the production problems and defects along with enhancements\n",
      "Used Rational Clear Case for the version control\n",
      "Used Maven as the build tool.\n",
      "Used J-Unit Testing and Ant Scripts.\n",
      "Used JIRA for tracking the Project Stories in AGILE Methodology.\n",
      "\n",
      "Environment: Agile, Java, JDK, J2EE, HTML5, CSS3, Java Script, JQuery, Ajax, AngularJS, Mongo DB, XML, Spring, Apache Camel, MVC design patterns, Spring MVC, Hibernate, Ant, Maven, Netflix, Rational Clear Case, Web sphere Server, IBM Web Sphere, Apache Camel, SOAP UI, JNDI, Log4J, PostgreSQL, MySQL Server, Google cloud platform, JIRA, RMI, IntelliJ, IDE, LINUX. \n",
      "Client: Cigna Healthcare\t\t\t\t\t\t\t\t\t              Nov 13– Dec 15 Location: Windsor, CT\n",
      "Role: Java Developer\n",
      "\n",
      "Description: One view is a web based application helping Customer Services people to view Benefit Plan information for Customers, health care providers. The application helps to resolve; track customer queries online by reducing overall time. The current project is reengineering the old application by replacing outdated Cordiant service layer with Restful Services and Spring Integration frame work improving performance and scalability.\n",
      "\n",
      "Responsibilities:\n",
      "Designed and developed the REST based Micro Services using the Spring Boot.\n",
      "Writing end-to-end flow i.e. controllers classes, service classes, DAOs classes as per the Spring MVC design and writing business logics using core java API and data structures\n",
      "Design, develop & deliver the REST APIs that are necessary to support new feature development and enhancements in an agile environment. \n",
      "Used Spring JMS related MDB to receive the messages from other team with IBMMQ for queuing\n",
      "Developed presentation layer code, using JSP, HTML, AJAX and JQuery\n",
      "Developed the Business layer using spring (IOC, AOP), DTO, and JTA\n",
      "Developed the Persistence layer DAO using HIBERNATE\n",
      "Worked with Open symphony workflows and delivered work flow module to the client. \n",
      "Developed the project using industry standard design patterns like Singleton, Business Delegate Factory Pattern for better maintenance of code and re-usability\n",
      "Developing application module coded on Spring Batch and Apache Camel. \n",
      "Written Jenkins pipeline template script in Groovy programming language for the automation of build and deployment process.\n",
      "Created groovy scripts to extract transaction volume information and email to management on daily basis. \n",
      "Developed unit test cases using Junit framework for testing accuracy of code and logging with SLF4j + Log4j\n",
      "Worked with defect tracking system Clear Quest\n",
      "Worked with IDE as Spring STS and deployed into spring tomcat server, WebSphere 6 & used Maven as build tool\n",
      "Responsible for code sanity in integration stream used Clear Case as version control tool.\n",
      "\n",
      "Environment: Java, J2EE, HTML, CSS, AJAX, JQuery, MongoDB, Apache Camel, symphony, JavaScript, JSP, Spring, Spring Batch, Spring web services, XML, UML, JUNIT, IBM WebSphere, Maven, Clear Case, SoapUI, Oracle 11g, Spring JMS, IBM MQ.\n",
      "\n",
      "Client: Liberty Mutual\t\t                                                           \t\t\t                                 Jan 12 - July 13  \n",
      "Location: Seattle, WA\n",
      "Role: Java Developer\n",
      "\n",
      "Description: Liberty Mutual Insurance is an American diversified global insurer, and the second-largest property and casualty insurer in the United States. Ecommerce application provides services such as Auto Insurance and home insurance. The application is used for accessibility into the appropriate Agent Center applications and generating quotes and policies, payments and reports.\n",
      "\n",
      "Responsibilities:\n",
      "Involved in all phases of the Software development life cycle (SDLC).\n",
      "Designed project related documents which includes Use case, Class and Sequence diagrams.\n",
      "Involved in design, development, testing and implementation of the process systems, working on iterative life cycles business requirements, and creating Detail Design Document.\n",
      "Using Agile methodologies to plan work for every iteration and used continuous integration tool to make the build passes before deploying the code to other environments.\n",
      "Extensive experience in developing PL/SQL Stored Procedures, Functions, Packages, Cursors, Collections (Nested tables and arrays), Records, Object types and Database Triggers. \n",
      "Created HTML Wireframes based in the Detailed System Specification Document Developed the presentation layer of the application using MVC architecture of spring framework. \n",
      "Created DAO classes to interact with DB2 database.\n",
      "Used Spring ORM module to integrate with Hibernate.\n",
      "Used JMS API for sending and receiving the messages on the queue.\n",
      "Used the spring validation and Tiles Framework in the presentation layer.\n",
      "Developed user interface using JSP, Spring Tag Libraries to simplify the complexities of the application.\n",
      "Developed user interface with Java Server Pages, Ajax support to speed up the application form filling.\n",
      "Used Apache Axis as the Web Service framework for creating and consuming Web Service clients using SOAP and WSDL.\n",
      "Used Rally for tracking purpose.\n",
      "Designed various tables required for the project using DB2 database. Used JBOSS server for deploying the application.\n",
      "Used Ant for build, create JAR, WAR, EAR files and deploy the EAR files automatically. \n",
      "Used Junit to test the application classes.\n",
      "Used Log4J to capture the logging information.\n",
      "\n",
      "Environment: Java, J2EE, JavaScript, JSP, AJAX, XML, Agile, Spring, Eclipse IDE, DB2, Rational Rose, Log4j, Junit, Ant, JBOSS, Rally, Apache Axis, Web Service, SOAP, WSDL.\n",
      "\n",
      "Client: Soft Pro Systems Ltd.                                                                                                                                             Sep 10 - Dec 11\n",
      "Location: Hyderabad, India\t\t\t\t\t\t\t\n",
      "Role:  Java Developer  \n",
      "\n",
      "Description: This project is mainly an Intranet application meant for employees in the organization. They are Intranet mailing System, Chatting, File Transfer and Remote Login. This project is based on the client server methodology.\n",
      "\n",
      "Responsibilities: \n",
      "Involved in the design and development of an entire Module – Guided Set Up. Developed user interface through JSP and Servlets. \n",
      "Developed Action classes and Action Forms using the struts framework. \n",
      "Developed Customs tags to display dynamic contents and to avoid large amounts of java code in JSP pages\n",
      "Connected to database through JDBC. \n",
      "Extensive experience working with XML (DOM and SAX).\n",
      "Used SQL-server to store the items in the database.\n",
      "Used Session beans for navigation of steps.\n",
      "Used Entity beans for storing the database in to database. Developed Session Beans as the clients of Entity Beans to maintain the Client state.\n",
      "Developed Ant Scripts to build and deploy EAR files on to Tomcat Server. Analyzed the EJB performance in terms of scalability by various Loads, Stress tests using Bean- test tool.\n",
      "Extensively used Eclipse while writing code as IDE. Written complex SQL queries, stored procedures, functions and triggers in PL/SQL. \n",
      "Developed test cases and used Junit for Unit Testing. \n",
      "Used CVS for version controlling.\n",
      "\n",
      "Environment: Java, J2EE, Servlets, XML (DOM and SAX), JSP, EJB, JavaScript, CSS, JDBC, Struts, Ant, Web Logic Application Server, WSAD, Eclipse IDE, SQL-Server, Apache Tomcat, Oracle, PL/SQL, CVS, PVCS, Junit, Windows.\n",
      "\n",
      "Client: \tLogin IT Technologies\t\t\t                                                                                                      May 09 - Aug 10 Location: Hyderabad, India\n",
      "Role: Java Developer\n",
      "\n",
      "Description:  PRS or Price reporting system is responsible to publish the rates to the customers and as to maintain the\n",
      "users across the FedEx locations and its subsidiaries. It interacts with the customer fusion and existing legacy systems to\n",
      "access the customer information and legacy data.\n",
      "\n",
      "Responsibilities:\n",
      "Developed web application using Struts 2.X, JSP, Servlets, Java beans that uses MVC design pattern\n",
      "Created user-friendly GUI interface and Web pages using HTML, CSS and JSP\n",
      "Wrote JavaScript for client-side validation.\n",
      "Used Eclipse as IDE tool for creating Servlets, JSP, and XML.\n",
      "Wrote SQL for JDBC prepared statements to retrieve the data from database.\n",
      "Monitored the logs using Log4J and fixed the problem\n",
      "The application was deployed on the Tomcat.\n",
      "Involved in build and deploying the application using ANT  \n",
      "Used CVS as version control system \n",
      "Worked on bug fixing and Production Support\n",
      "\n",
      "Environment: Java, JDBC, Struts, JavaScript, HTML, CSS, JSP, Servlets, Tomcat, Oracle, Eclipse IDE, CVS, ANT, Log4J.\n"
     ]
    }
   ],
   "source": [
    "# function extracting text from docx format\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_document(document):\n",
    "    doc = Document(document)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "text = extract_text_from_document(r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\\Achyuth Resume_8.docx\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chromaDB(summarized_text):\n",
    "    collection.add(\n",
    "        documents=[summarized_text],\n",
    "        ids=[str(hash(summarized_text))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"extracted_text\"],\n",
    "    template = '''You are an AI assistant specialized in extracting and summarizing key information from provided CVs. Given a CV, analyze it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    CV:\n",
    "    {extracted_text}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "        \"Full Name\": \"[Extracted Full Name]\",\n",
    "        \"Email\": \"[Extracted Email Address]\",\n",
    "        \"Phone Number\": \"[Extracted Phone Number]\",\n",
    "        \"Location\": \"[City, Country (if mentioned)]\",\n",
    "        \"LinkedIn\": \"[Extracted LinkedIn Profile URL (if available)]\",\n",
    "        \"Portfolio/Website\": \"[Extracted Portfolio or Website URL (if available)]\",\n",
    "        \"Education\": [\n",
    "            \n",
    "                \"Degree\": \"[Extracted Degree]\",\n",
    "                \"University\": \"[Extracted University Name]\",\n",
    "                \"Year of Graduation\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Work Experience\": [\n",
    "            \n",
    "                \"Job Title\": \"[Extracted Job Title]\",\n",
    "                \"Company Name\": \"[Extracted Company Name]\",\n",
    "                \"Location\": \"[City, Country / Remote]\",\n",
    "                \"Employment Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "                \"Duration\": \"[Start Date - End Date (if available)]\",\n",
    "                \"Key Responsibilities\": [\n",
    "                    \"Summarized responsibility 1\",\n",
    "                    \"Summarized responsibility 2\",\n",
    "                    \"Summarized responsibility 3\"\n",
    "                ]\n",
    "            \n",
    "        ],\n",
    "        \"Skills\": [\n",
    "            \"Extracted skill 1\",\n",
    "            \"Extracted skill 2\",\n",
    "            \"Extracted skill 3\"\n",
    "        ],\n",
    "        \"Certifications\": [\n",
    "            \n",
    "                \"Certification Name\": \"[Extracted Certification Name]\",\n",
    "                \"Issuing Organization\": \"[Extracted Organization Name]\",\n",
    "                \"Year\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Projects\": [\n",
    "            \n",
    "                \"Project Name\": \"[Extracted Project Name]\",\n",
    "                \"Description\": \"[Short project summary]\",\n",
    "                \"Technologies Used\": [\"Tech 1\", \"Tech 2\"]\n",
    "            \n",
    "        ],\n",
    "        \"Languages\": [\n",
    "            \"Extracted language 1\",\n",
    "            \"Extracted language 2\"\n",
    "        ],\n",
    "        \"Achievements\": [\n",
    "            \"Mentioned achievement 1\",\n",
    "            \"Mentioned achievement 2\"\n",
    "        ]\n",
    "\n",
    "    ### **Guidelines:**\n",
    "    - Ensure the JSON output is valid and properly formatted.\n",
    "    - Omit any section if the relevant information is not available in the CV.\n",
    "    - Keep responses concise and free from unnecessary text.\n",
    "    - Do not include any additional explanations—only return pure JSON.\n",
    "\n",
    "    Omit empty data Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.\n",
    "\n",
    "    \"COMPULSORY\"\n",
    "    Keep the token size of text to be not more than 4000 that is why extract only really important information.\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "def cv_summary(extrated_text):\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    summarized_text = chain.run(extracted_text=extrated_text)\n",
    "    return summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "folder_path = r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\"\n",
    "\n",
    "MAX_REQUESTS_PER_MINUTE = 1  # Adjust based on API limits\n",
    "INTERVAL = 60 / MAX_REQUESTS_PER_MINUTE  # Time gap between requests\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file in os.scandir(folder_path):\n",
    "    if i < 4:  # Process only 10 files\n",
    "        extracted_text = extract_text_from_document(file)\n",
    "        summarized_text = cv_summary(extracted_text)\n",
    "        save_to_chromaDB(summarized_text)\n",
    "\n",
    "        i += 1\n",
    "        print(f\"Processed {i} files\")\n",
    "\n",
    "        time.sleep(INTERVAL)  # Wait to maintain rate limit\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = '''About the job\n",
    "Data Analyst Intern (Paid)\n",
    "\n",
    "Company: WebBoost Solutions by UM\n",
    "\n",
    "Location: Remot\n",
    "\n",
    "Duration: 3 months\n",
    "\n",
    "Opportunity: Full-time based on performance, with a Certificate of Internship\n",
    "\n",
    "Application Deadline: 4th April 2025\n",
    "\n",
    "About WebBoost Solutions by UM\n",
    "\n",
    "WebBoost Solutions by UM provides students and graduates with hands-on experience in data analysis, helping them enhance their career prospects.\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "✅ Collect, clean, and analyze datasets.\n",
    "\n",
    "✅ Develop reports and data visualizations for business insights.\n",
    "\n",
    "✅ Identify trends and patterns in data to support decision-making.\n",
    "\n",
    "✅ Collaborate with teams to present data-driven recommendations.\n",
    "\n",
    "Requirements\n",
    "\n",
    "🎓 Enrolled in or a graduate of a relevant program (Data Science, Business Analytics, Computer Science, or related field).\n",
    "\n",
    "📊 Strong analytical skills and attention to detail.\n",
    "\n",
    "🐍 Familiarity with tools like Excel, SQL, or Python (preferred).\n",
    "\n",
    "🤝 Excellent communication and teamwork abilities.\n",
    "\n",
    "Benefits\n",
    "\n",
    "💰 Stipend: ₹7,500 - ₹15,000 (Performance-Based) (Paid)\n",
    "\n",
    "✔ Real-world data analysis experience.\n",
    "\n",
    "✔ Internship Certificate & Letter of Recommendation.\n",
    "\n",
    "✔ Build your portfolio with impactful projects.\n",
    "\n",
    "How to Apply\n",
    "\n",
    "📩 Submit your application by 4th April 2025 with the subject: \"Data Analyst Intern Application\".\n",
    "\n",
    "Equal Opportunity\n",
    "\n",
    "WebBoost Solutions by UM is an equal-opportunity employer, welcoming applicants from all backgrounds.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template='''You are an AI assistant specialized in extracting and summarizing key information from job descriptions. Given a job description, analyze \n",
    "    it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "    \"Job Title\": \"[Extracted Job Title]\",\n",
    "    \"Company Name\": \"[Extracted Company Name (if available)]\",\n",
    "    \"Location\": \"[City, Country / Remote]\",\n",
    "    \"Job Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "    \"Key Responsibilities\": [\n",
    "        \"Summarized primary duty 1\",\n",
    "        \"Summarized primary duty 2\",\n",
    "        \"Summarized primary duty 3\"\n",
    "    ],\n",
    "    \"Required Skills\": [\n",
    "        \"Extracted technical or soft skill 1\",\n",
    "        \"Extracted technical or soft skill 2\"\n",
    "    ],\n",
    "    \"Preferred Qualifications\": [\n",
    "        \"Optional qualification 1 (if mentioned)\",\n",
    "        \"Optional qualification 2 (if mentioned)\"\n",
    "    ],\n",
    "    \"Experience Required\": \"[Years of experience (if specified)]\",\n",
    "    \"Salary Range\": \"[Salary details (if mentioned)]\",\n",
    "    \"How to Apply\": \"[Application link or email (if available)]\"\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    Ensure the JSON output is valid and properly formatted.\n",
    "\n",
    "    Omit any section if the relevant information is not available in the job description.\n",
    "\n",
    "    Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.No back ticks.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "response = chain.run(job_description=job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Job Title\": \"Data Analyst Intern\",\n",
      "    \"Company Name\": \"WebBoost Solutions by UM\",\n",
      "    \"Location\": \"Remote\",\n",
      "    \"Job Type\": \"Internship\",\n",
      "    \"Key Responsibilities\": [\n",
      "        \"Collect, clean, and analyze datasets\",\n",
      "        \"Develop reports and data visualizations for business insights\",\n",
      "        \"Identify trends and patterns in data to support decision-making\",\n",
      "        \"Collaborate with teams to present data-driven recommendations\"\n",
      "    ],\n",
      "    \"Required Skills\": [\n",
      "        \"Strong analytical skills and attention to detail\",\n",
      "        \"Excellent communication and teamwork abilities\"\n",
      "    ],\n",
      "    \"Preferred Qualifications\": [\n",
      "        \"Familiarity with tools like Excel, SQL, or Python\"\n",
      "    ],\n",
      "    \"Experience Required\": \"None\",\n",
      "    \"Salary Range\": \"₹7,500 - ₹15,000 (Performance-Based)\",\n",
      "    \"How to Apply\": \"Submit application by 4th April 2025 with the subject: Data Analyst Intern Application\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jd_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template = \"Find CVs that match this description: {job_description}\"\n",
    ")\n",
    "\n",
    "formatted_jd_prompt_template = jd_prompt_template.format(job_description=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving top 80% match\n",
    "num_vectors = collection.count()\n",
    "num_vectors = int(0.8*(num_vectors))\n",
    "def query(formatted_jd_prompt_template,num_vectors):\n",
    "    results = collection.query(\n",
    "    query_texts=[formatted_jd_prompt_template],  \n",
    "    n_results=num_vectors,  # Retrieve top 5 matches\n",
    "    include=[\"documents\"]\n",
    "    )\n",
    "    documents = results.get(\"documents\", [])  # Get the list of documents\n",
    "    extracted_data = [{\"name\": doc[\"Full Name\"], \"email\": doc[\"Email\"]} for doc in documents]\n",
    "    return extracted_data\n",
    "    \n",
    "result = query(formatted_jd_prompt_template,num_vectors)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
