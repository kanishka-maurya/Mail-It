{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# downloading dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "# downloading dataset\n",
    "import kaggle\n",
    "import os\n",
    "\n",
    "path = \"artifacts/dataset/\"\n",
    "dataset = \"palaksood97/resume-dataset\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    kaggle.api.dataset_download_files(dataset= dataset, path= path, unzip= True)\n",
    "    print(f\"Dataset: {dataset} downloaded successfully! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# function extracting text from docx format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_document\u001b[39m(document):\n\u001b[0;32m      5\u001b[0m     doc \u001b[38;5;241m=\u001b[39m Document(document)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'docx'"
     ]
    }
   ],
   "source": [
    "# function extracting text from docx format\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_document(document):\n",
    "    doc = Document(document)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "text = extract_text_from_document(r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\\Achyuth Resume_8.docx\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chromaDB(summarized_text):\n",
    "    collection.add(\n",
    "        documents=[summarized_text],\n",
    "        ids=[str(hash(summarized_text))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"extracted_text\"],\n",
    "    template = '''You are an AI assistant specialized in extracting and summarizing key information from provided CVs. Given a CV, analyze it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    CV:\n",
    "    {extracted_text}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "        \"Full Name\": \"[Extracted Full Name]\",\n",
    "        \"Email\": \"[Extracted Email Address]\",\n",
    "        \"Phone Number\": \"[Extracted Phone Number]\",\n",
    "        \"Location\": \"[City, Country (if mentioned)]\",\n",
    "        \"LinkedIn\": \"[Extracted LinkedIn Profile URL (if available)]\",\n",
    "        \"Portfolio/Website\": \"[Extracted Portfolio or Website URL (if available)]\",\n",
    "        \"Education\": [\n",
    "            \n",
    "                \"Degree\": \"[Extracted Degree]\",\n",
    "                \"University\": \"[Extracted University Name]\",\n",
    "                \"Year of Graduation\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Work Experience\": [\n",
    "            \n",
    "                \"Job Title\": \"[Extracted Job Title]\",\n",
    "                \"Company Name\": \"[Extracted Company Name]\",\n",
    "                \"Location\": \"[City, Country / Remote]\",\n",
    "                \"Employment Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "                \"Duration\": \"[Start Date - End Date (if available)]\",\n",
    "                \"Key Responsibilities\": [\n",
    "                    \"Summarized responsibility 1\",\n",
    "                    \"Summarized responsibility 2\",\n",
    "                    \"Summarized responsibility 3\"\n",
    "                ]\n",
    "            \n",
    "        ],\n",
    "        \"Skills\": [\n",
    "            \"Extracted skill 1\",\n",
    "            \"Extracted skill 2\",\n",
    "            \"Extracted skill 3\"\n",
    "        ],\n",
    "        \"Certifications\": [\n",
    "            \n",
    "                \"Certification Name\": \"[Extracted Certification Name]\",\n",
    "                \"Issuing Organization\": \"[Extracted Organization Name]\",\n",
    "                \"Year\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Projects\": [\n",
    "            \n",
    "                \"Project Name\": \"[Extracted Project Name]\",\n",
    "                \"Description\": \"[Short project summary]\",\n",
    "                \"Technologies Used\": [\"Tech 1\", \"Tech 2\"]\n",
    "            \n",
    "        ],\n",
    "        \"Languages\": [\n",
    "            \"Extracted language 1\",\n",
    "            \"Extracted language 2\"\n",
    "        ],\n",
    "        \"Achievements\": [\n",
    "            \"Mentioned achievement 1\",\n",
    "            \"Mentioned achievement 2\"\n",
    "        ]\n",
    "\n",
    "    ### **Guidelines:**\n",
    "    - Ensure the JSON output is valid and properly formatted.\n",
    "    - Omit any section if the relevant information is not available in the CV.\n",
    "    - Keep responses concise and free from unnecessary text.\n",
    "    - Do not include any additional explanationsâ€”only return pure JSON.\n",
    "\n",
    "    Omit empty data Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.\n",
    "\n",
    "    \"COMPULSORY\"\n",
    "    Keep the token size of text to be not more than 4000 that is why extract only really important information.\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "def cv_summary(extrated_text):\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    summarized_text = chain.run(extracted_text=extrated_text)\n",
    "    return summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "folder_path = r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\"\n",
    "\n",
    "MAX_REQUESTS_PER_MINUTE = 1  # Adjust based on API limits\n",
    "INTERVAL = 60 / MAX_REQUESTS_PER_MINUTE  # Time gap between requests\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file in os.scandir(folder_path):\n",
    "    if i < 4:  # Process only 10 files\n",
    "        extracted_text = extract_text_from_document(file)\n",
    "        summarized_text = cv_summary(extracted_text)\n",
    "        save_to_chromaDB(summarized_text)\n",
    "\n",
    "        i += 1\n",
    "        print(f\"Processed {i} files\")\n",
    "\n",
    "        time.sleep(INTERVAL)  # Wait to maintain rate limit\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = '''About the job\n",
    "Data Analyst Intern (Paid)\n",
    "\n",
    "Company: WebBoost Solutions by UM\n",
    "\n",
    "Location: Remot\n",
    "\n",
    "Duration: 3 months\n",
    "\n",
    "Opportunity: Full-time based on performance, with a Certificate of Internship\n",
    "\n",
    "Application Deadline: 4th April 2025\n",
    "\n",
    "About WebBoost Solutions by UM\n",
    "\n",
    "WebBoost Solutions by UM provides students and graduates with hands-on experience in data analysis, helping them enhance their career prospects.\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "âœ… Collect, clean, and analyze datasets.\n",
    "\n",
    "âœ… Develop reports and data visualizations for business insights.\n",
    "\n",
    "âœ… Identify trends and patterns in data to support decision-making.\n",
    "\n",
    "âœ… Collaborate with teams to present data-driven recommendations.\n",
    "\n",
    "Requirements\n",
    "\n",
    "ðŸŽ“ Enrolled in or a graduate of a relevant program (Data Science, Business Analytics, Computer Science, or related field).\n",
    "\n",
    "ðŸ“Š Strong analytical skills and attention to detail.\n",
    "\n",
    "ðŸ Familiarity with tools like Excel, SQL, or Python (preferred).\n",
    "\n",
    "ðŸ¤ Excellent communication and teamwork abilities.\n",
    "\n",
    "Benefits\n",
    "\n",
    "ðŸ’° Stipend: â‚¹7,500 - â‚¹15,000 (Performance-Based) (Paid)\n",
    "\n",
    "âœ” Real-world data analysis experience.\n",
    "\n",
    "âœ” Internship Certificate & Letter of Recommendation.\n",
    "\n",
    "âœ” Build your portfolio with impactful projects.\n",
    "\n",
    "How to Apply\n",
    "\n",
    "ðŸ“© Submit your application by 4th April 2025 with the subject: \"Data Analyst Intern Application\".\n",
    "\n",
    "Equal Opportunity\n",
    "\n",
    "WebBoost Solutions by UM is an equal-opportunity employer, welcoming applicants from all backgrounds.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template='''You are an AI assistant specialized in extracting and summarizing key information from job descriptions. Given a job description, analyze \n",
    "    it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "    \"Job Title\": \"[Extracted Job Title]\",\n",
    "    \"Company Name\": \"[Extracted Company Name (if available)]\",\n",
    "    \"Location\": \"[City, Country / Remote]\",\n",
    "    \"Job Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "    \"Key Responsibilities\": [\n",
    "        \"Summarized primary duty 1\",\n",
    "        \"Summarized primary duty 2\",\n",
    "        \"Summarized primary duty 3\"\n",
    "    ],\n",
    "    \"Required Skills\": [\n",
    "        \"Extracted technical or soft skill 1\",\n",
    "        \"Extracted technical or soft skill 2\"\n",
    "    ],\n",
    "    \"Preferred Qualifications\": [\n",
    "        \"Optional qualification 1 (if mentioned)\",\n",
    "        \"Optional qualification 2 (if mentioned)\"\n",
    "    ],\n",
    "    \"Experience Required\": \"[Years of experience (if specified)]\",\n",
    "    \"Salary Range\": \"[Salary details (if mentioned)]\",\n",
    "    \"How to Apply\": \"[Application link or email (if available)]\"\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    Ensure the JSON output is valid and properly formatted.\n",
    "\n",
    "    Omit any section if the relevant information is not available in the job description.\n",
    "\n",
    "    Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.No back ticks.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "response = chain.run(job_description=job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Job Title\": \"Data Analyst Intern\",\n",
      "    \"Company Name\": \"WebBoost Solutions by UM\",\n",
      "    \"Location\": \"Remote\",\n",
      "    \"Job Type\": \"Internship\",\n",
      "    \"Key Responsibilities\": [\n",
      "        \"Collect, clean, and analyze datasets\",\n",
      "        \"Develop reports and data visualizations for business insights\",\n",
      "        \"Identify trends and patterns in data to support decision-making\",\n",
      "        \"Collaborate with teams to present data-driven recommendations\"\n",
      "    ],\n",
      "    \"Required Skills\": [\n",
      "        \"Strong analytical skills and attention to detail\",\n",
      "        \"Excellent communication and teamwork abilities\"\n",
      "    ],\n",
      "    \"Preferred Qualifications\": [\n",
      "        \"Familiarity with tools like Excel, SQL, or Python\"\n",
      "    ],\n",
      "    \"Experience Required\": \"None\",\n",
      "    \"Salary Range\": \"â‚¹7,500 - â‚¹15,000 (Performance-Based)\",\n",
      "    \"How to Apply\": \"Submit application by 4th April 2025 with the subject: Data Analyst Intern Application\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jd_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template = \"Find CVs that match this description: {job_description}\"\n",
    ")\n",
    "\n",
    "formatted_jd_prompt_template = jd_prompt_template.format(job_description=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving top 80% match\n",
    "num_vectors = collection.count()\n",
    "num_vectors = int(0.8*(num_vectors))\n",
    "def query(formatted_jd_prompt_template,num_vectors):\n",
    "    results = collection.query(\n",
    "    query_texts=[formatted_jd_prompt_template],  \n",
    "    n_results=num_vectors,  # Retrieve top 5 matches\n",
    "    include=[\"documents\"]\n",
    "    )\n",
    "    documents = results.get(\"documents\", [])  # Get the list of documents\n",
    "    extracted_data = [{\"name\": doc[\"Full Name\"], \"email\": doc[\"Email\"]} for doc in documents]\n",
    "    return extracted_data\n",
    "    \n",
    "result = query(formatted_jd_prompt_template,num_vectors)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
