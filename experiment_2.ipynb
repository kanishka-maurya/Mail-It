{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# downloading dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "# downloading dataset\n",
    "import kaggle\n",
    "import os\n",
    "\n",
    "path = \"artifacts/dataset/\"\n",
    "dataset = \"palaksood97/resume-dataset\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    kaggle.api.dataset_download_files(dataset= dataset, path= path, unzip= True)\n",
    "    print(f\"Dataset: {dataset} downloaded successfully! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# function extracting text from docx format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_document\u001b[39m(document):\n\u001b[0;32m      5\u001b[0m     doc \u001b[38;5;241m=\u001b[39m Document(document)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'docx'"
     ]
    }
   ],
   "source": [
    "# function extracting text from docx format\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_document(document):\n",
    "    doc = Document(document)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "text = extract_text_from_document(r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\\Achyuth Resume_8.docx\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chromaDB(summarized_text):\n",
    "    collection.add(\n",
    "        documents=[summarized_text],\n",
    "        ids=[str(hash(summarized_text))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"extracted_text\"],\n",
    "    template = '''You are an AI assistant specialized in extracting and summarizing key information from provided CVs. Given a CV, analyze it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    CV:\n",
    "    {extracted_text}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "        \"Full Name\": \"[Extracted Full Name]\",\n",
    "        \"Email\": \"[Extracted Email Address]\",\n",
    "        \"Phone Number\": \"[Extracted Phone Number]\",\n",
    "        \"Location\": \"[City, Country (if mentioned)]\",\n",
    "        \"LinkedIn\": \"[Extracted LinkedIn Profile URL (if available)]\",\n",
    "        \"Portfolio/Website\": \"[Extracted Portfolio or Website URL (if available)]\",\n",
    "        \"Education\": [\n",
    "            \n",
    "                \"Degree\": \"[Extracted Degree]\",\n",
    "                \"University\": \"[Extracted University Name]\",\n",
    "                \"Year of Graduation\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Work Experience\": [\n",
    "            \n",
    "                \"Job Title\": \"[Extracted Job Title]\",\n",
    "                \"Company Name\": \"[Extracted Company Name]\",\n",
    "                \"Location\": \"[City, Country / Remote]\",\n",
    "                \"Employment Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "                \"Duration\": \"[Start Date - End Date (if available)]\",\n",
    "                \"Key Responsibilities\": [\n",
    "                    \"Summarized responsibility 1\",\n",
    "                    \"Summarized responsibility 2\",\n",
    "                    \"Summarized responsibility 3\"\n",
    "                ]\n",
    "            \n",
    "        ],\n",
    "        \"Skills\": [\n",
    "            \"Extracted skill 1\",\n",
    "            \"Extracted skill 2\",\n",
    "            \"Extracted skill 3\"\n",
    "        ],\n",
    "        \"Certifications\": [\n",
    "            \n",
    "                \"Certification Name\": \"[Extracted Certification Name]\",\n",
    "                \"Issuing Organization\": \"[Extracted Organization Name]\",\n",
    "                \"Year\": \"[Year (if available)]\"\n",
    "            \n",
    "        ],\n",
    "        \"Projects\": [\n",
    "            \n",
    "                \"Project Name\": \"[Extracted Project Name]\",\n",
    "                \"Description\": \"[Short project summary]\",\n",
    "                \"Technologies Used\": [\"Tech 1\", \"Tech 2\"]\n",
    "            \n",
    "        ],\n",
    "        \"Languages\": [\n",
    "            \"Extracted language 1\",\n",
    "            \"Extracted language 2\"\n",
    "        ],\n",
    "        \"Achievements\": [\n",
    "            \"Mentioned achievement 1\",\n",
    "            \"Mentioned achievement 2\"\n",
    "        ]\n",
    "\n",
    "    ### **Guidelines:**\n",
    "    - Ensure the JSON output is valid and properly formatted.\n",
    "    - Omit any section if the relevant information is not available in the CV.\n",
    "    - Keep responses concise and free from unnecessary text.\n",
    "    - Do not include any additional explanations—only return pure JSON.\n",
    "\n",
    "    Omit empty data Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.\n",
    "\n",
    "    \"COMPULSORY\"\n",
    "    Keep the token size of text to be not more than 4000 that is why extract only really important information.\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "def cv_summary(extrated_text):\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    summarized_text = chain.run(extracted_text=extrated_text)\n",
    "    return summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "folder_path = r\"C:\\Users\\kanis\\Mail-It\\artifacts\\dataset\\Resumes\"\n",
    "\n",
    "MAX_REQUESTS_PER_MINUTE = 1  # Adjust based on API limits\n",
    "INTERVAL = 60 / MAX_REQUESTS_PER_MINUTE  # Time gap between requests\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file in os.scandir(folder_path):\n",
    "    if i < 4:  # Process only 10 files\n",
    "        extracted_text = extract_text_from_document(file)\n",
    "        summarized_text = cv_summary(extracted_text)\n",
    "        save_to_chromaDB(summarized_text)\n",
    "\n",
    "        i += 1\n",
    "        print(f\"Processed {i} files\")\n",
    "\n",
    "        time.sleep(INTERVAL)  # Wait to maintain rate limit\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = '''About the job\n",
    "Data Analyst Intern (Paid)\n",
    "\n",
    "Company: WebBoost Solutions by UM\n",
    "\n",
    "Location: Remot\n",
    "\n",
    "Duration: 3 months\n",
    "\n",
    "Opportunity: Full-time based on performance, with a Certificate of Internship\n",
    "\n",
    "Application Deadline: 4th April 2025\n",
    "\n",
    "About WebBoost Solutions by UM\n",
    "\n",
    "WebBoost Solutions by UM provides students and graduates with hands-on experience in data analysis, helping them enhance their career prospects.\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "✅ Collect, clean, and analyze datasets.\n",
    "\n",
    "✅ Develop reports and data visualizations for business insights.\n",
    "\n",
    "✅ Identify trends and patterns in data to support decision-making.\n",
    "\n",
    "✅ Collaborate with teams to present data-driven recommendations.\n",
    "\n",
    "Requirements\n",
    "\n",
    "🎓 Enrolled in or a graduate of a relevant program (Data Science, Business Analytics, Computer Science, or related field).\n",
    "\n",
    "📊 Strong analytical skills and attention to detail.\n",
    "\n",
    "🐍 Familiarity with tools like Excel, SQL, or Python (preferred).\n",
    "\n",
    "🤝 Excellent communication and teamwork abilities.\n",
    "\n",
    "Benefits\n",
    "\n",
    "💰 Stipend: ₹7,500 - ₹15,000 (Performance-Based) (Paid)\n",
    "\n",
    "✔ Real-world data analysis experience.\n",
    "\n",
    "✔ Internship Certificate & Letter of Recommendation.\n",
    "\n",
    "✔ Build your portfolio with impactful projects.\n",
    "\n",
    "How to Apply\n",
    "\n",
    "📩 Submit your application by 4th April 2025 with the subject: \"Data Analyst Intern Application\".\n",
    "\n",
    "Equal Opportunity\n",
    "\n",
    "WebBoost Solutions by UM is an equal-opportunity employer, welcoming applicants from all backgrounds.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template='''You are an AI assistant specialized in extracting and summarizing key information from job descriptions. Given a job description, analyze \n",
    "    it and return a structured summary in valid JSON format, capturing only the most essential details.\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Return the following output strictly in the JSON format:\n",
    "\n",
    "    \"Job Title\": \"[Extracted Job Title]\",\n",
    "    \"Company Name\": \"[Extracted Company Name (if available)]\",\n",
    "    \"Location\": \"[City, Country / Remote]\",\n",
    "    \"Job Type\": \"[Full-time / Part-time / Contract / Internship]\",\n",
    "    \"Key Responsibilities\": [\n",
    "        \"Summarized primary duty 1\",\n",
    "        \"Summarized primary duty 2\",\n",
    "        \"Summarized primary duty 3\"\n",
    "    ],\n",
    "    \"Required Skills\": [\n",
    "        \"Extracted technical or soft skill 1\",\n",
    "        \"Extracted technical or soft skill 2\"\n",
    "    ],\n",
    "    \"Preferred Qualifications\": [\n",
    "        \"Optional qualification 1 (if mentioned)\",\n",
    "        \"Optional qualification 2 (if mentioned)\"\n",
    "    ],\n",
    "    \"Experience Required\": \"[Years of experience (if specified)]\",\n",
    "    \"Salary Range\": \"[Salary details (if mentioned)]\",\n",
    "    \"How to Apply\": \"[Application link or email (if available)]\"\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    Ensure the JSON output is valid and properly formatted.\n",
    "\n",
    "    Omit any section if the relevant information is not available in the job description.\n",
    "\n",
    "    Keep responses concise and free from unnecessary text.There should be no header and text \n",
    "    mentioning what you have done, it should just be pure JSON.No back ticks.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "response = chain.run(job_description=job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Job Title\": \"Data Analyst Intern\",\n",
      "    \"Company Name\": \"WebBoost Solutions by UM\",\n",
      "    \"Location\": \"Remote\",\n",
      "    \"Job Type\": \"Internship\",\n",
      "    \"Key Responsibilities\": [\n",
      "        \"Collect, clean, and analyze datasets\",\n",
      "        \"Develop reports and data visualizations for business insights\",\n",
      "        \"Identify trends and patterns in data to support decision-making\",\n",
      "        \"Collaborate with teams to present data-driven recommendations\"\n",
      "    ],\n",
      "    \"Required Skills\": [\n",
      "        \"Strong analytical skills and attention to detail\",\n",
      "        \"Excellent communication and teamwork abilities\"\n",
      "    ],\n",
      "    \"Preferred Qualifications\": [\n",
      "        \"Familiarity with tools like Excel, SQL, or Python\"\n",
      "    ],\n",
      "    \"Experience Required\": \"None\",\n",
      "    \"Salary Range\": \"₹7,500 - ₹15,000 (Performance-Based)\",\n",
      "    \"How to Apply\": \"Submit application by 4th April 2025 with the subject: Data Analyst Intern Application\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jd_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template = \"Find CVs that match this description: {job_description}\"\n",
    ")\n",
    "\n",
    "formatted_jd_prompt_template = jd_prompt_template.format(job_description=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving top 80% match\n",
    "num_vectors = collection.count()\n",
    "num_vectors = int(0.8*(num_vectors))\n",
    "def query(formatted_jd_prompt_template,num_vectors):\n",
    "    results = collection.query(\n",
    "    query_texts=[formatted_jd_prompt_template],  \n",
    "    n_results=num_vectors,  # Retrieve top 5 matches\n",
    "    include=[\"documents\"]\n",
    "    )\n",
    "    documents = results.get(\"documents\", [])  # Get the list of documents\n",
    "    extracted_data = [{\"name\": doc[\"Full Name\"], \"email\": doc[\"Email\"]} for doc in documents]\n",
    "    return extracted_data\n",
    "    \n",
    "result = query(formatted_jd_prompt_template,num_vectors)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
